{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d574e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# CATEGORY MAP & FEATURE LIST\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "categories_map = {\n",
    "    'Input 1': [1,2],\n",
    "    'Input 2': list(range(1,6)),\n",
    "    'Input 3': list(range(1,6)),\n",
    "    'Input 4': list(range(1,22)),\n",
    "    'Input 5': list(range(1,6)),\n",
    "    'Input 6': [1,2,3],\n",
    "    'Input 7': [1,2,3,4],\n",
    "    'Input 8': list(range(1,11)),\n",
    "}\n",
    "all_inputs     = [f'Input {i}' for i in range(1,19) if i != 12]\n",
    "numeric_inputs = [f'Input {i}' for i in range(9,19) if i != 12]\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# MLP CLASS\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "class MLPNet(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dims, activations):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        dims = [in_dim] + hidden_dims\n",
    "        for i, h in enumerate(hidden_dims):\n",
    "            layers.append(nn.Linear(dims[i], dims[i+1]))\n",
    "            act = activations[i].lower()\n",
    "            if act == 'relu':\n",
    "                layers.append(nn.ReLU())\n",
    "            elif act == 'tanh':\n",
    "                layers.append(nn.Tanh())\n",
    "            elif act == 'sigmoid':\n",
    "                layers.append(nn.Sigmoid())\n",
    "            elif act == 'softplus':\n",
    "                layers.append(nn.Softplus())\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown activation '{activations[i]}'\")\n",
    "        layers.append(nn.Linear(dims[-1], 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# SWEEP & SAVE FUNCTION\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "def sweep_save_samples_mlp(\n",
    "    model_path: str,\n",
    "    norms_json: str,\n",
    "    hidden_dims: list[int],\n",
    "    activations: list[str],\n",
    "    test_csv: str,\n",
    "    output_csv: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Sweeps Input 10 over [0,3000] for each test sample and saves results:\n",
    "      Row 0: sample indices\n",
    "      Row 1: (true_input10|true_output) for each sample\n",
    "      Rows 2+: each row begins with grid Input 10, then model predictions\n",
    "    \"\"\"\n",
    "    # 0) load norms\n",
    "    with open(norms_json, 'r') as f:\n",
    "        norms = json.load(f)\n",
    "    y_mean, y_std        = norms['y_mean'], norms['y_std']\n",
    "    feat_mean, feat_std  = norms['feat_mean'], norms['feat_std']\n",
    "\n",
    "    # 1) load test data\n",
    "    df = pd.read_csv(test_csv)\n",
    "    N = len(df)\n",
    "    y_true   = df['Output'].to_numpy(float)\n",
    "    x10_true = df['Input 10'].to_numpy(float)\n",
    "\n",
    "    # 2) build normalized feature matrix Z_np\n",
    "    X = df[all_inputs].copy()\n",
    "    for col, cats in categories_map.items():\n",
    "        if col not in X: continue\n",
    "        X[col] = pd.Categorical(X[col], categories=cats)\n",
    "        dummies = pd.get_dummies(X[col], prefix=col)\n",
    "        for c in cats:\n",
    "            key = f\"{col}_{c}\"\n",
    "            if key not in dummies:\n",
    "                dummies[key] = 0\n",
    "        X = pd.concat([X.drop(columns=[col]), dummies], axis=1)\n",
    "    for col in numeric_inputs:\n",
    "        X[col] = (X[col] - feat_mean[col]) / feat_std[col]\n",
    "    Z_np_full = X.to_numpy(dtype=np.float32)\n",
    "\n",
    "    # 3) infer feature dimension from checkpoint\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    ckpt = torch.load(model_path, map_location=device)\n",
    "    first_w = ckpt.get('net.0.weight', next(iter(ckpt.values())))\n",
    "    in_dim = first_w.shape[1]\n",
    "    # adjust columns if mismatch\n",
    "    if Z_np_full.shape[1] > in_dim:\n",
    "        Z_np = Z_np_full[:, :in_dim]\n",
    "    elif Z_np_full.shape[1] < in_dim:\n",
    "        pad = np.zeros((N, in_dim - Z_np_full.shape[1]), dtype=np.float32)\n",
    "        Z_np = np.hstack([Z_np_full, pad])\n",
    "    else:\n",
    "        Z_np = Z_np_full\n",
    "\n",
    "    # 4) load model\n",
    "    model = MLPNet(in_dim, hidden_dims, activations).to(device)\n",
    "    model.load_state_dict(ckpt)\n",
    "    model.eval()\n",
    "\n",
    "    # 5) sweep parameters\n",
    "    grid  = np.linspace(0, 3000, 101)\n",
    "    mu10  = feat_mean['Input 10']\n",
    "    sig10 = feat_std['Input 10']\n",
    "    idx10 = all_inputs.index('Input 10')\n",
    "\n",
    "    preds = np.zeros((len(grid), N), dtype=float)\n",
    "    with torch.no_grad():\n",
    "        for i in range(N):\n",
    "            base = np.repeat(Z_np[i:i+1], len(grid), axis=0)\n",
    "            base[:, idx10] = (grid - mu10) / sig10\n",
    "            out_norm = model(torch.from_numpy(base).to(device)).cpu().numpy().ravel()\n",
    "            preds[:, i] = out_norm * y_std + y_mean\n",
    "\n",
    "    # 6) write results to CSV\n",
    "    with open(output_csv, 'w') as f:\n",
    "        # Row 0: sample indices, preceded by empty col\n",
    "        f.write(',' + ','.join(str(i) for i in range(N)) + '\\n')\n",
    "        # Row 1: true values with \"|\" separator in tuple\n",
    "        f.write(',' + ','.join(f\"({x10_true[i]:.4f}|{y_true[i]:.4f})\"\n",
    "                                for i in range(N)) + '\\n')\n",
    "        # Rows 2+: each starts with grid value, then predictions\n",
    "        for j, g in enumerate(grid):\n",
    "            f.write(f\"{g:.4f},\" +\n",
    "                    ','.join(f\"{preds[j,i]:.6f}\" for i in range(N)) + '\\n')\n",
    "\n",
    "    print(f\"Sweep data saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59fcb483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sweep data saved to sweep_results.csv\n"
     ]
    }
   ],
   "source": [
    "sweep_save_samples_mlp(\n",
    "    model_path   = \"/home/kamiar/chevron/Acid-neural-net/First Data-V3/58c0fccc/58c0fccc_fold4.pth\",\n",
    "    norms_json   = \"/home/kamiar/chevron/Acid-neural-net/First Data-V3/58c0fccc/58c0fccc_norms.json\",\n",
    "    hidden_dims  = [4, 4],\n",
    "    activations  = ['softplus','softplus'],\n",
    "    test_csv     = \"/home/kamiar/chevron/Acid-neural-net/First Data-V3/data/test.csv\",\n",
    "    output_csv   = \"sweep_results.csv\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
