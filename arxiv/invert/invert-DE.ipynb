{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6481d4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "# --- 1) Load your trained model and scalers ---\n",
    "\n",
    "# Reconstruct the PyTorch architecture you used for training\n",
    "def build_model(input_dim, hidden_dims, activation='ReLU'):\n",
    "    act_key = activation.strip().lower()\n",
    "    layers = []\n",
    "    in_dim = input_dim\n",
    "    for h in hidden_dims:\n",
    "        layers.append(nn.Linear(in_dim, h))\n",
    "        if act_key not in ('linear', 'none'):\n",
    "            layers.append(getattr(nn, activation)())\n",
    "        in_dim = h\n",
    "    layers.append(nn.Linear(in_dim, 1))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "# Paths to your saved artifacts\n",
    "MODEL_PATH    = 'trained_model_ab12cd34.pt'\n",
    "SCALER_X_PATH = 'scaler_X.pkl'\n",
    "SCALER_Y_PATH = 'scaler_y.pkl'\n",
    "\n",
    "# Load model\n",
    "hidden_dims = [64, 32]   # must match training\n",
    "activation  = 'ReLU'\n",
    "# we'll infer input_dim from scaler_X\n",
    "with open(SCALER_X_PATH, 'rb') as f:\n",
    "    scaler_X = pickle.load(f)\n",
    "with open(SCALER_Y_PATH, 'rb') as f:\n",
    "    scaler_y = pickle.load(f)\n",
    "\n",
    "input_dim = sum(len(v) for v in {\n",
    "    'Input 1': [1,2],\n",
    "    'Input 2': [1,2,3,4,5],\n",
    "    'Input 3': [1,2,3,4,5],\n",
    "    'Input 4': list(range(1,18)),\n",
    "    'Input 5': list(range(1,6)),\n",
    "    'Input 6': [1,2,3],\n",
    "    'Input 7': [1,2,3,4],\n",
    "    'Input 8': list(range(1,11))\n",
    "}.values()) + scaler_X.scale_.shape[0]\n",
    "\n",
    "model = build_model(input_dim, hidden_dims, activation)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.eval()\n",
    "\n",
    "# --- 2) Definitions for inversion ---\n",
    "\n",
    "# Fixed inputs (all except Input 10)\n",
    "fixed_inputs = {\n",
    "    'Input 1':  2,\n",
    "    'Input 2':  3,\n",
    "    'Input 3':  1,\n",
    "    'Input 4': 10,\n",
    "    'Input 5':  4,\n",
    "    'Input 6':  2,\n",
    "    'Input 7':  1,\n",
    "    'Input 8':  7,\n",
    "    'Input 9':  123.4,\n",
    "    # 'Input 10' is what we’ll solve for\n",
    "    'Input 11': 0.56,\n",
    "    'Input 12':  78.9,\n",
    "    'Input 13':   0.002,\n",
    "    'Input 14': 12345.0,\n",
    "    'Input 15':  200.0,\n",
    "    'Input 16':  12.3,\n",
    "    'Input 17': 4567.8,\n",
    "    'Input 18':   9.1,\n",
    "}\n",
    "\n",
    "# Desired true output (in original scale)\n",
    "desired_output =  25000.0\n",
    "\n",
    "# Convert desired output to normalized scale\n",
    "desired_norm = scaler_y.transform([[desired_output]]).ravel()[0]\n",
    "\n",
    "# Fixed category definitions\n",
    "categories_map = {\n",
    "    'Input 1': [1, 2],\n",
    "    'Input 2': [1, 2, 3, 4, 5],\n",
    "    'Input 3': [1, 2, 3, 4, 5],\n",
    "    'Input 4': list(range(1, 18)),\n",
    "    'Input 5': list(range(1, 6)),\n",
    "    'Input 6': [1, 2, 3],\n",
    "    'Input 7': [1, 2, 3, 4],\n",
    "    'Input 8': list(range(1, 11)),\n",
    "}\n",
    "\n",
    "# Build a single feature‐vector function given a candidate x10\n",
    "def make_feature_vector(x10):\n",
    "    # 1) Categorical one‐hots for Inputs 1–8\n",
    "    cat_parts = []\n",
    "    for i in range(1, 9):\n",
    "        name = f'Input {i}'\n",
    "        cats = categories_map[name]\n",
    "        val  = fixed_inputs[name]\n",
    "        # build one-hot in fixed order\n",
    "        onehot = [1.0 if val == c else 0.0 for c in cats]\n",
    "        cat_parts.extend(onehot)\n",
    "    # 2) Numeric inputs 9–18 (including variable Input 10)\n",
    "    num_names = [f'Input {i}' for i in range(9, 19)]\n",
    "    num_vals  = []\n",
    "    for nm in num_names:\n",
    "        if nm == 'Input 10':\n",
    "            num_vals.append(x10)\n",
    "        else:\n",
    "            num_vals.append(fixed_inputs[nm])\n",
    "    num_arr = np.array(num_vals, dtype=np.float32).reshape(1, -1)\n",
    "    # 3) Normalize numeric\n",
    "    num_scaled = (num_arr - scaler_X.mean_) / scaler_X.scale_\n",
    "    # 4) Concatenate\n",
    "    X = np.hstack([np.array(cat_parts, dtype=np.float32).reshape(1, -1),\n",
    "                   num_scaled.astype(np.float32)])\n",
    "    return X\n",
    "\n",
    "# Objective: squared error in normalized output\n",
    "def objective(x):\n",
    "    X = make_feature_vector(x[0])\n",
    "    with torch.no_grad():\n",
    "        pred_norm = model(torch.from_numpy(X)).cpu().numpy().ravel()[0]\n",
    "    return (pred_norm - desired_norm)**2\n",
    "\n",
    "# Bounds for Input 10 (choose appropriate range)\n",
    "bounds = [(0.0, 1000.0)]   # adjust min/max to domain of Input 10\n",
    "\n",
    "# --- 3) Run differential evolution ---\n",
    "result = differential_evolution(objective, bounds, maxiter=200, tol=1e-6)\n",
    "x10_opt = result.x[0]\n",
    "\n",
    "# 4) Report\n",
    "print(f\"Optimal Input 10 (unscaled): {x10_opt:.6f}\")\n",
    "\n",
    "# Verify final prediction\n",
    "X_opt = make_feature_vector(x10_opt)\n",
    "with torch.no_grad():\n",
    "    pred_norm = model(torch.from_numpy(X_opt)).cpu().numpy().ravel()[0]\n",
    "pred_orig = scaler_y.inverse_transform([[pred_norm]])[0,0]\n",
    "print(f\"Predicted output at this Input 10: {pred_orig:.4f} \"\n",
    "      f\"(target was {desired_output})\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
